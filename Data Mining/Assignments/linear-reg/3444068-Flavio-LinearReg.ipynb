{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\lib\\site-packages\\ipykernel\\__main__.py:147: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\nC:\\Python27\\lib\\site-packages\\ipykernel\\__main__.py:148: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\nC:\\Python27\\lib\\site-packages\\ipykernel\\__main__.py:149: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================\n  Euclidian Squared\n============================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared Mean Error Evolution History:\n[ 22812.55249929  22812.55249929  22812.55249929  22812.55249929\n  20004.06742849  20004.06742849  20004.06742849  20004.06742849\n  20004.06742849  20004.06742849  20004.06742849  20004.06742849\n  20004.06742849  20004.06742849  20004.06742849  20004.06742849\n  20004.06742849  20004.06742849  20004.06742849  20004.06742849\n  20004.06742849  20004.06742849  20004.06742849  20004.06742849\n  20004.06742849  20004.06742849  20004.06742849  20004.06742849\n  20004.06742849  20004.06742849  20004.06742849  20004.06742849\n  20004.06742849  20004.06742849  20004.06742849  20004.06742849\n  20004.06742849  18306.13749924  18306.13749924  18306.13749924\n  18306.13749924  18306.13749924  18306.13749924  18306.13749924\n  18306.13749924  18306.13749924  18306.13749924  18306.13749924\n  18306.13749924  18306.13749924  18306.13749924  15951.17509668\n  15951.17509668  15951.17509668  15951.17509668  15951.17509668\n  15951.17509668  15951.17509668  15951.17509668  15951.17509668\n  15951.17509668  15951.17509668  15951.17509668  15951.17509668\n  15951.17509668  15951.17509668  15951.17509668  15951.17509668\n  15951.17509668  15951.17509668  15951.17509668  15951.17509668\n  15951.17509668  15951.17509668  15951.17509668  15951.17509668\n  15951.17509668  15951.17509668  15951.17509668  15951.17509668\n  15951.17509668  15951.17509668  15951.17509668  15951.17509668\n  15951.17509668  15951.17509668  15951.17509668  15951.17509668\n  15951.17509668  15951.17509668  15951.17509668  15951.17509668\n  15951.17509668  15951.17509668  15951.17509668  15951.17509668\n  15951.17509668  15951.17509668  15951.17509668  15951.17509668]\n('Coefficients: \\n', array([ 161.64988274,    4.2824937 ,  -14.75453981,    1.0111247 ,\n         38.12353558,   26.97976957,   56.48537236,  -68.8364483 ,\n        -13.45775962]))\nMean squared error: 22780.17\n\n============================================================================\n  Manhattan\n============================================================================\nSquared Mean Error Evolution History:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27061.40276558  21344.16094136  16897.44439234  16897.44439234\n  16897.44439234  16897.44439234  16897.44439234  16897.44439234\n  16897.44439234  16897.44439234  16897.44439234  16897.44439234\n  16897.44439234  16897.44439234  16897.44439234  16897.44439234\n  15030.0783624   15030.0783624   15030.0783624   15030.0783624\n  15030.0783624   15030.0783624   15030.0783624   15030.0783624\n  15030.0783624   15030.0783624   15030.0783624   15030.0783624\n  15030.0783624   15030.0783624   15030.0783624   15030.0783624\n  15030.0783624   15030.0783624   15030.0783624   15030.0783624\n  15030.0783624   15030.0783624   15030.0783624   15030.0783624\n  15030.0783624   15030.0783624   15030.0783624   15030.0783624\n  15030.0783624   15030.0783624   11604.70352578  11604.70352578\n  11604.70352578  11604.70352578  11604.70352578  11604.70352578\n  11604.70352578  11604.70352578  11604.70352578  11604.70352578\n  11604.70352578  11604.70352578  11604.70352578  11604.70352578\n  11604.70352578  11604.70352578  11604.70352578  11604.70352578\n  11604.70352578  11604.70352578  11604.70352578  11604.70352578\n  11604.70352578  11604.70352578  11604.70352578  11604.70352578\n  11604.70352578  11604.70352578  11604.70352578  11604.70352578\n  11604.70352578  11604.70352578  11604.70352578  11604.70352578\n  11604.70352578  11604.70352578  11604.70352578  11604.70352578\n  11604.70352578  11604.70352578  11604.70352578  11604.70352578\n  11604.70352578  11604.70352578  11604.70352578  11604.70352578\n  11604.70352578  11604.70352578  11604.70352578  11604.70352578\n  11604.70352578  11604.70352578  11604.70352578  11604.70352578]\n\n('Coefficients: \\n', array([ 183.43008117,   -8.90505383,  -20.99759341,    2.29720096,\n         10.02543208,   56.52978179,   49.80624741,  -76.96889827,\n         -7.314179  ]))\nMean squared error: 22246.75\n\n============================================================================\n  Angular\n============================================================================\nSquared Mean Error Evolution History:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20631.32727372  20631.32727372  20631.32727372  20631.32727372\n  20631.32727372  20631.32727372  20631.32727372  20631.32727372\n  20631.32727372  20631.32727372  19802.91366402  19802.91366402\n  19802.91366402  19802.91366402  19802.91366402  19802.91366402\n  19802.91366402  19000.34393358  19000.34393358  19000.34393358\n  19000.34393358  19000.34393358  19000.34393358  19000.34393358\n  19000.34393358  19000.34393358  19000.34393358  19000.34393358\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  15457.94271571  15457.94271571  15457.94271571\n  15457.94271571  14637.54338156  14637.54338156  14637.54338156\n  14637.54338156  14637.54338156  14637.54338156  14637.54338156]\n('Coefficients: \\n', array([ 168.27441767,   22.85387086,  -20.30264536,    1.05300521,\n         29.43120624,   36.14346936,   56.64162137,  -79.35745183,\n        -14.97609346]))\nMean squared error: 23903.25\n\n============================================================================\n  Scikit Learn\n============================================================================\n('Coefficients: \\n', [array([   45.817697  ,    -6.07662556,    21.33179471,    48.31303004,\n        1123.7748093 ,  -726.45560959,  -444.59298105,  -209.45330308]), 233.03345684697496])\nMean squared error: 293530.89\n\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "#                               Metric Utils\n",
    "# ============================================================================\n",
    "\n",
    "from __future__ import division\n",
    "import math\n",
    "\n",
    "\n",
    "def count(dataset):\n",
    "    \"\"\"() | Counts how many elements in dataset.\"\"\"\n",
    "    return len(dataset)\n",
    "\n",
    "\n",
    "def mean(dataset):\n",
    "    \"\"\"() | The mean value for dataset.\"\"\"\n",
    "    rv = 0\n",
    "    for x in dataset:\n",
    "        rv += x\n",
    "    return rv / count(dataset)\n",
    "\n",
    "\n",
    "def mode(dataset):\n",
    "    \"\"\"() | The most frequent element in dataset.\"\"\"\n",
    "    myset = []\n",
    "    myindex = []\n",
    "    mycount = []\n",
    "    for i in xrange(count(dataset)):\n",
    "        elem = dataset[i]\n",
    "        if elem in myset:\n",
    "            pos = myset.index(elem)\n",
    "            mycount[pos] += 1\n",
    "        else:\n",
    "            myset.append(dataset[i])\n",
    "            myindex.append(i)\n",
    "            mycount.append(1)\n",
    "\n",
    "    rv = myset[0]\n",
    "    freq = mycount[0]\n",
    "    for j in xrange(len(mycount)):\n",
    "        if freq < mycount[j]:\n",
    "            freq = mycount[0]\n",
    "            rv = myset[j]\n",
    "    return rv\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "#                               Distance Utils\n",
    "# ============================================================================\n",
    "def distanceEuclid2(point1, point2):\n",
    "    \"\"\"Squared Euclidean distance\"\"\"\n",
    "    rv = 0\n",
    "    for i in xrange(len(point1)):\n",
    "        rv += (point1[i] - point2[i]) ** 2\n",
    "    return rv\n",
    "\n",
    "\n",
    "def distanceManhattan(point1, point2):\n",
    "    \"\"\"Manhattan distance between two points\"\"\"\n",
    "    rv = 0\n",
    "    for i in xrange(len(point1)):\n",
    "        rv += math.fabs(point1[i] - point2[i])\n",
    "    return rv\n",
    "\n",
    "\n",
    "def distanceAngular(point1, point2):\n",
    "    \"\"\"\n",
    "    A value in range [0,1].\n",
    "    0 means same angle;\n",
    "    1 means opposite direction.\n",
    "    0.5 is perpendicular.\n",
    "    Formula: 0.5 * ( 1 - sign(cos(t)) * cos(t)**2 )\n",
    "    \"\"\"\n",
    "    dot = 0  # Dot product\n",
    "    n1 = 0  # Norm of point1 (squared)\n",
    "    n2 = 0  # Norm of point2 (squared)\n",
    "    for i in xrange(len(point1)):\n",
    "        dot += point1[i] * point2[i]\n",
    "        n1 += point1[i] * point1[i]\n",
    "        n2 += point2[i] * point2[i]\n",
    "\n",
    "    if 0 == dot:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return (1 - (math.copysign(dot * dot, dot) / (n1 * n2))) / 2\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "#                            Linear Regression Class\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "\n",
    "class MultiLinearRegression(object):\n",
    "    # =========================================================================\n",
    "    #   Constants\n",
    "    # =========================================================================\n",
    "    EUCLID2 = \"euclid2\"\n",
    "    MANHATTAN = \"manhattan\"\n",
    "    ANGULAR = \"angular\"\n",
    "    PASSES = 100\n",
    "    BASE_ALPHA = 0.1\n",
    "    BASE_WEIGHT = 0.01\n",
    "\n",
    "    # =========================================================================\n",
    "    #   Constructor\n",
    "    # =========================================================================\n",
    "    def __init__(self, trainingSet):\n",
    "        \"\"\"Knn classifier algorithm. knn(trainingSet)\"\"\"\n",
    "        self.setTrainingSet(trainingSet)\n",
    "        self.setDistanceFunction(self.EUCLID2)\n",
    "        self.resetWeights(self.BASE_WEIGHT)\n",
    "\n",
    "    # =========================================================================\n",
    "    #   Setters\n",
    "    # =========================================================================\n",
    "    def setTrainingSet (self, trainingSet):\n",
    "        self.trainingSet = trainingSet\n",
    "        self.rows = len(self.trainingSet)\n",
    "        self.columns = len(self.trainingSet[0])\n",
    "        self.setAnswerColumn(self.columns - 1)\n",
    "        self.updateCrossValidationSet()\n",
    "\n",
    "    def setAnswerColumn(self, answerColumn):\n",
    "        \"\"\"Set the answer column\"\"\"\n",
    "        self.answerColumn = answerColumn\n",
    "        self.setFeatureColumns(answerColumn)\n",
    "\n",
    "    def setFeatureColumns(self, answerColumn):\n",
    "        \"\"\"Caches a copy of trainingSet without the answer column\"\"\"\n",
    "        # Prepends column of 1's\n",
    "        self.features = np.empty([self.rows, self.columns])\n",
    "        self.features[:, 1:] = np.delete(self.trainingSet.copy(), answerColumn, axis=1)\n",
    "        self.features[0][0] = 1 # Prevents zscore from dividing by zero\n",
    "        self.features = stats.zscore(self.features)\n",
    "        self.features[:, 0] = np.ones([self.rows])\n",
    "\n",
    "    def updateCrossValidationSet (self):\n",
    "        splitPoint = 0.5*self.rows\n",
    "        self.valFeatures = self.features[splitPoint:, :]\n",
    "        self.valAnswers = self.trainingSet[splitPoint:, self.answerColumn]\n",
    "        self.features = self.features[:splitPoint, :]\n",
    "\n",
    "    def setDistanceFunction(self, distanceFunctionCode):\n",
    "        \"\"\"Sets the metric used\"\"\"\n",
    "        if self.EUCLID2 == distanceFunctionCode:\n",
    "            self.distanceFunction = distanceEuclid2\n",
    "        elif self.MANHATTAN == distanceFunctionCode:\n",
    "            self.distanceFunction = distanceManhattan\n",
    "        else:\n",
    "            self.distanceFunction = distanceAngular\n",
    "\n",
    "    def resetWeights (self, value):\n",
    "        \"\"\"Reset weights to the given argument\"\"\"\n",
    "        self.weights = np.ones(self.columns) * value\n",
    "\n",
    "    # =========================================================================\n",
    "    #   Getters\n",
    "    # =========================================================================\n",
    "    def getAnswer(self, i):\n",
    "        \"\"\"Returns classifier, given the row index\"\"\"\n",
    "        return self.trainingSet[i][self.answerColumn]\n",
    "\n",
    "    # =========================================================================\n",
    "    #   Prediction\n",
    "    # =========================================================================\n",
    "    def fit(self):\n",
    "        self.resetWeights(self.BASE_WEIGHT)\n",
    "        oldTrainingSet = self.trainingSet.copy()    # Backup\n",
    "\n",
    "        errorHistory = np.empty([self.PASSES])\n",
    "        alphaAging = 1\n",
    "        lastValError = np.mean((self.predict(self.weights, self.valFeatures) - self.valAnswers) ** 2)\n",
    "        for passIterator in xrange(self.PASSES):\n",
    "            # Shuffles training set\n",
    "            self.setTrainingSet(np.random.permutation(self.trainingSet))\n",
    "\n",
    "            # Fits\n",
    "            trainRows = len(self.features)\n",
    "\n",
    "            for setIterator in xrange(trainRows):\n",
    "                error = self.getAnswer(setIterator) - self.predict(self.weights, self.features[setIterator])\n",
    "                newWeights = np.add(self.weights,\n",
    "                        (self.BASE_ALPHA * trainRows/(trainRows+alphaAging)) * error * self.features[setIterator])\n",
    "\n",
    "                # Validation\n",
    "                newValError = np.mean((self.predict(newWeights, self.valFeatures) - self.valAnswers) ** 2)\n",
    "                if (newValError <= lastValError):\n",
    "                    self.weights = newWeights\n",
    "                    lastValError = newValError\n",
    "                    alphaAging += 1\n",
    "\n",
    "            errorHistory[passIterator] = lastValError\n",
    "            # errorHistory[passIterator] = np.mean((self.predict(self.weights, self.valFeatures) - self.valAnswers) ** 2)\n",
    "\n",
    "        self.setTrainingSet(oldTrainingSet)\n",
    "        return errorHistory\n",
    "\n",
    "    def predict(self, weights, pointSamples):\n",
    "        \"\"\"Predicts the value of a given feature array\"\"\"\n",
    "        return np.dot(pointSamples, weights)\n",
    "\n",
    "    def naivePredict(self, weights, pointSamples):\n",
    "        if (len(pointSamples[0]) < len(weights)):\n",
    "            newSamples = np.empty([len(pointSamples), len(weights)])\n",
    "            newSamples[:, 1:] = pointSamples\n",
    "            newSamples[:, 0] = np.ones([len(pointSamples)])\n",
    "            return self.predict(weights, newSamples)\n",
    "        return self.predict(weights, pointSamples)\n",
    "\n",
    "    # =========================================================================\n",
    "    #   Analysis\n",
    "    # =========================================================================\n",
    "    def score(self, predictedValues, answers):\n",
    "        \"\"\"Compares two results\"\"\"\n",
    "        if len(predictedValues) != len(answers):\n",
    "            raise NameError(\"[knn] Impossible to generate score (different dimensions)\")\n",
    "\n",
    "        meanAbsoluteError = sum(abs(real - pred) for real, pred in zip(predictedValues, answers))[0]\n",
    "        meanAbsoluteError /= len(answers)\n",
    "        print \"Error:    \", meanAbsoluteError\n",
    "        return meanAbsoluteError\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "#                                   Usage\n",
    "# ============================================================================\n",
    "\n",
    "# Loading and Shuffling dataset\n",
    "data = np.loadtxt(\"hour.csv\", delimiter=\",\")\n",
    "# data = data[:, 1:]\n",
    "\n",
    "# Using only:\n",
    "# holyday, weekday, workingday, weathersit, temp, atemp, hum, windspeed\n",
    "trimedData = data[:, 6:15]\n",
    "trimedData[:, 8] = data[:, 16]\n",
    "data = trimedData\n",
    "ndata = np.random.permutation(data)\n",
    "\n",
    "# Separating features\n",
    "ROW_COUNT = len(ndata)\n",
    "COLUMN_COUNT = len(data[0])\n",
    "nt = int(math.floor(ROW_COUNT * 0.01))\n",
    "nf = int(math.floor(ROW_COUNT * 0.02))\n",
    "\n",
    "# Prediction\n",
    "ttfeatures = stats.zscore(ndata[nt:nf, 0:COLUMN_COUNT-1])  # Features\n",
    "ttlabels = ndata[nt:nf, COLUMN_COUNT-1]                    # Answers\n",
    "\n",
    "\n",
    "# Creating learner\n",
    "regr = MultiLinearRegression(ndata[:nt, :])\n",
    "\n",
    "# Euclidean distance\n",
    "print \"============================================================================\"\n",
    "print \"  Euclidian Squared\"\n",
    "print \"============================================================================\"\n",
    "regr.setDistanceFunction(regr.EUCLID2)\n",
    "evolutionHistory = regr.fit()\n",
    "print \"Squared Mean Error Evolution History:\"\n",
    "print evolutionHistory\n",
    "predictions = regr.naivePredict(regr.weights, ttfeatures)\n",
    "print('Coefficients: \\n', regr.weights)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((predictions - ttlabels) ** 2))\n",
    "print \"\"\n",
    "\n",
    "# Manhattan distance\n",
    "print \"============================================================================\"\n",
    "print \"  Manhattan\"\n",
    "print \"============================================================================\"\n",
    "regr.setDistanceFunction(regr.MANHATTAN)\n",
    "print \"Squared Mean Error Evolution History:\"\n",
    "evolutionHistory = regr.fit()\n",
    "print evolutionHistory\n",
    "predictions = regr.naivePredict(regr.weights, ttfeatures)\n",
    "print \"\"\n",
    "print('Coefficients: \\n', regr.weights)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((predictions - ttlabels) ** 2))\n",
    "print \"\"\n",
    "\n",
    "# Angular distance\n",
    "print \"============================================================================\"\n",
    "print \"  Angular\"\n",
    "print \"============================================================================\"\n",
    "regr.setDistanceFunction(regr.ANGULAR)\n",
    "print \"Squared Mean Error Evolution History:\"\n",
    "evolutionHistory = regr.fit()\n",
    "print evolutionHistory\n",
    "predictions = regr.naivePredict(regr.weights, ttfeatures)\n",
    "print('Coefficients: \\n', regr.weights)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((predictions - ttlabels) ** 2))\n",
    "print \"\"\n",
    "\n",
    "\n",
    "print \"============================================================================\"\n",
    "print \"  Scikit Learn\"\n",
    "print \"============================================================================\"\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(ndata[:nt, :COLUMN_COUNT-1], ndata[:nt, COLUMN_COUNT-1])\n",
    "predictions = regr.predict(ttfeatures)\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', [regr.coef_ , regr.intercept_])\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((predictions - ttlabels) ** 2))\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "## O erro obtido pelo SKLearn foi cerca de 13 vezes maior do que o erro obtido no trabalho. Foram utilizadas as seguintes metodologias:\n",
    "### 1. Seleção de colunas:\n",
    "#### holiday, weekday, workingday, weathersit, temp, atemp, hum, windspeed\n",
    "\n",
    "### 2. \"Normalização\" das features pela função zscore:\n",
    "#### Na função setFeatureColumns:\n",
    "#### Linha 141 ....... self.features = stats.zscore(self.features)\t\n",
    "\n",
    "### 3. Implementação de envelhecimento de aprendizado. O alpha diminui ao longo das iterações baseado no tamanho do conjunto treino.\n",
    "#### Linha 108 ....... PASSES = 2000\n",
    "#### Linha 109 ....... BASE_ALPHA = 0.1\n",
    "#### Linha 110 ....... BASE_WEIGHT = 0.01\n",
    "#### ...\n",
    "#### Linha 172 ....... alphaAging = 1\n",
    "#### ...\n",
    "#### Linha 181 ....... self.weights = np.add(self.weights, (self.BASE_ALPHA * self.rows/(self.rows+alphaAging)) * error * self.features[setIterator])\n",
    "\n",
    "### 4. Os pesos são iniciados com 0.1 (um valor entre 0 e 1, considerando o standard score aplicado nas features). Sem o envelhecimento de aprendizado, o mais adequado seria 0.01 ou menos, mas o envelhecimento se encarrega da redução do passo até esses valores menores.\n",
    "\n",
    "### 5. O uso da estratégia de validação também foi extremamente positivo, reduzindo o erro quadrático médio da faixa de 40 a 50 mil para 20 a 30 mil, em alguns casos, o erro chegou a 18 mil.\n",
    "\n",
    "### 6. As métricas de distância (Euclidiana Quadrada, Manhattan ou Angular) não tiveram impacto significativo, nem apresentaram correlação aparente."
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}