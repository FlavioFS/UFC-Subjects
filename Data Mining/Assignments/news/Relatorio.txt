=====================================================================
 Preprocessamentos
=====================================================================
• Tokenização manual
    → Remoção de sinais gráficos e pontuação: [ ] ) ( @ # $ | , ! . : ; ?
    → Foram preservadas palavras com híven intermediário

• Remoção de Stop Words
    → Através do corpus do nltk para português:
        nltk.corpus.stopwords.words('portuguese')

• Stemming
    → Através do stemmer do nltk para português:
        nltk.stem.RSLPStemmer()


=====================================================================
 Classificadores Utilizados
=====================================================================
• Naive Bayes
• Entropia Máxima


=====================================================================
 Features
=====================================================================
• Total: 2κ features
    → κ raízes (stems) de palavras mais frequentes (κ features)
    → Frequência das κ palavras mais frequentes    (κ features)


=====================================================================
 Dificuldades
=====================================================================
• Foram utilizadas técnicas para o português, mas há textos em inglês,
  e textos praticamente numéricos na amostra, o que gera muito ruído.


=====================================================================
 Resultados
=====================================================================
• κ = 1
    → Naive Bayes: 0.407673860911
    → Maximum Entropy: 0.428057553957

• κ = 2
    → Naive Bayes: 0.468824940048
    → Maximum Entropy: 0.44964028777

• κ = 5
    → Naive Bayes: 0.465227817746
    → Maximum Entropy: 0.488009592326

• κ = 10
    → Naive Bayes: 0.47721822542
    → Maximum Entropy: 0.509592326139

• κ = 20
    → Naive Bayes: 0.448441247002
    → Maximum Entropy: 0.494004796163


=====================================================================
 Conclusões
=====================================================================
• Os classificadores são influenciados pela quantidade de features.

• A não utilização da frequência das palavras reduziu drasticamente a
  acurácia do classificador (aproximadamente de 50% para 20%).

• A segunda palavra tem grande impacto; as demais, não tanto.

• A feature κ-palavras mais frequentes aumenta a acurácia do classificador 
  proporcionalmente a κ apenas até o ponto em que a quantidade de palavras
  distintas se torna inferior a κ, ou seja, o vocabulário dos textos
  não é diversificado o bastante, e portanto, não existe a quantidade de
  radicais esperada: κ (nesses casos, utilizou-se todo o conjunto obtido).


=====================================================================
 Treinamentos do Maximum Entropy
=====================================================================
C:\Python27\python.exe "C:/Users/Kienz/GitHub/UFC-Subjects/Data Mining/Assignments/news/344068-Flavio-news.py"

• κ = 1
    ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -2.63906        0.018
             2          -1.27541        0.659
             3          -1.00982        0.751
             4          -0.85193        0.759
             5          -0.75088        0.765
             6          -0.68183        0.769
             7          -0.63193        0.777
             8          -0.59426        0.779
             9          -0.56480        0.785
            10          -0.54111        0.785
            11          -0.52164        0.787
            12          -0.50532        0.787
            13          -0.49143        0.785
            14          -0.47946        0.787
            15          -0.46903        0.787
            16          -0.45985        0.785
            17          -0.45169        0.785
            18          -0.44440        0.785
            19          -0.43784        0.787
            20          -0.43190        0.788
            21          -0.42649        0.788
            22          -0.42155        0.788
            23          -0.41700        0.788
            24          -0.41282        0.788
            25          -0.40894        0.787
            26          -0.40534        0.787
            27          -0.40199        0.788
            28          -0.39886        0.788
            29          -0.39592        0.788
            30          -0.39317        0.788
            31          -0.39058        0.788
            32          -0.38814        0.789
            33          -0.38584        0.789
            34          -0.38366        0.790
            35          -0.38159        0.790
            36          -0.37962        0.790
            37          -0.37776        0.790
            38          -0.37598        0.790
            39          -0.37428        0.791
            40          -0.37266        0.791
            41          -0.37111        0.791
            42          -0.36963        0.791
            43          -0.36821        0.793
            44          -0.36685        0.791
            45          -0.36554        0.791
            46          -0.36428        0.791
            47          -0.36307        0.791
            48          -0.36191        0.791
            49          -0.36079        0.791
            50          -0.35970        0.791
            51          -0.35866        0.791
            52          -0.35765        0.791
            53          -0.35667        0.791
            54          -0.35573        0.791
            55          -0.35482        0.791
            56          -0.35393        0.791
            57          -0.35307        0.791
            58          -0.35224        0.791
            59          -0.35144        0.791
            60          -0.35065        0.791
            61          -0.34989        0.791
            62          -0.34915        0.791
            63          -0.34843        0.793
            64          -0.34773        0.793
            65          -0.34705        0.793
            66          -0.34639        0.793
            67          -0.34574        0.793
            68          -0.34512        0.793
            69          -0.34450        0.793
            70          -0.34390        0.793
            71          -0.34332        0.793
            72          -0.34275        0.793
            73          -0.34220        0.793
            74          -0.34165        0.793
            75          -0.34112        0.793
            76          -0.34060        0.793
            77          -0.34010        0.793
            78          -0.33960        0.793
            79          -0.33912        0.793
            80          -0.33864        0.793
            81          -0.33818        0.793
            82          -0.33772        0.791
            83          -0.33728        0.791
            84          -0.33684        0.791
            85          -0.33641        0.791
            86          -0.33599        0.791
            87          -0.33558        0.791
            88          -0.33518        0.791
            89          -0.33479        0.793
            90          -0.33440        0.793
            91          -0.33402        0.793
            92          -0.33364        0.793
            93          -0.33328        0.793
            94          -0.33292        0.793
            95          -0.33256        0.793
            96          -0.33222        0.793
            97          -0.33188        0.793
            98          -0.33154        0.793
            99          -0.33121        0.793
         Final          -0.33089        0.793


• κ = 2
    ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -2.63906        0.018
             2          -1.22163        0.677
             3          -0.96179        0.813
             4          -0.79428        0.873
             5          -0.68035        0.900
             6          -0.59866        0.921
             7          -0.53738        0.926
             8          -0.48971        0.927
             9          -0.45153        0.929
            10          -0.42023        0.932
            11          -0.39407        0.935
            12          -0.37185        0.938
            13          -0.35272        0.939
            14          -0.33607        0.941
            15          -0.32141        0.942
            16          -0.30842        0.942
            17          -0.29680        0.947
            18          -0.28634        0.951
            19          -0.27688        0.951
            20          -0.26826        0.951
            21          -0.26038        0.952
            22          -0.25314        0.952
            23          -0.24647        0.953
            24          -0.24029        0.953
            25          -0.23456        0.953
            26          -0.22921        0.953
            27          -0.22422        0.954
            28          -0.21954        0.954
            29          -0.21516        0.954
            30          -0.21103        0.954
            31          -0.20713        0.954
            32          -0.20345        0.956
            33          -0.19997        0.956
            34          -0.19667        0.956
            35          -0.19353        0.956
            36          -0.19055        0.956
            37          -0.18771        0.957
            38          -0.18500        0.957
            39          -0.18241        0.957
            40          -0.17993        0.957
            41          -0.17756        0.957
            42          -0.17529        0.957
            43          -0.17311        0.957
            44          -0.17102        0.957
            45          -0.16900        0.957
            46          -0.16707        0.957
            47          -0.16520        0.957
            48          -0.16340        0.957
            49          -0.16167        0.957
            50          -0.15999        0.957
            51          -0.15838        0.957
            52          -0.15681        0.957
            53          -0.15530        0.957
            54          -0.15383        0.957
            55          -0.15242        0.957
            56          -0.15104        0.957
            57          -0.14971        0.958
            58          -0.14841        0.958
            59          -0.14715        0.958
            60          -0.14593        0.958
            61          -0.14475        0.958
            62          -0.14359        0.958
            63          -0.14247        0.958
            64          -0.14138        0.958
            65          -0.14031        0.958
            66          -0.13928        0.959
            67          -0.13826        0.959
            68          -0.13728        0.959
            69          -0.13632        0.959
            70          -0.13538        0.959
            71          -0.13447        0.959
            72          -0.13357        0.959
            73          -0.13270        0.959
            74          -0.13185        0.959
            75          -0.13101        0.959
            76          -0.13020        0.959
            77          -0.12940        0.959
            78          -0.12862        0.959
            79          -0.12786        0.959
            80          -0.12711        0.959
            81          -0.12638        0.959
            82          -0.12566        0.959
            83          -0.12496        0.960
            84          -0.12427        0.960
            85          -0.12360        0.960
            86          -0.12294        0.960
            87          -0.12229        0.960
            88          -0.12165        0.960
            89          -0.12103        0.960
            90          -0.12041        0.959
            91          -0.11981        0.959
            92          -0.11922        0.959
            93          -0.11864        0.959
            94          -0.11807        0.959
            95          -0.11751        0.959
            96          -0.11696        0.959
            97          -0.11642        0.959
            98          -0.11589        0.959
            99          -0.11537        0.959
         Final          -0.11486        0.959


• κ = 5
    ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -2.63906        0.018
             2          -1.21129        0.674
             3          -0.94323        0.849
             4          -0.76114        0.947
             5          -0.63523        0.969
             6          -0.54478        0.974
             7          -0.47719        0.975
             8          -0.42494        0.975
             9          -0.38340        0.977
            10          -0.34963        0.977
            11          -0.32163        0.977
            12          -0.29806        0.977
            13          -0.27794        0.977
            14          -0.26058        0.977
            15          -0.24543        0.977
            16          -0.23211        0.977
            17          -0.22030        0.977
            18          -0.20977        0.977
            19          -0.20031        0.977
            20          -0.19176        0.977
            21          -0.18402        0.977
            22          -0.17695        0.977
            23          -0.17049        0.977
            24          -0.16455        0.977
            25          -0.15908        0.977
            26          -0.15402        0.977
            27          -0.14933        0.977
            28          -0.14497        0.977
            29          -0.14090        0.977
            30          -0.13710        0.977
            31          -0.13354        0.977
            32          -0.13020        0.977
            33          -0.12706        0.977
            34          -0.12411        0.977
            35          -0.12131        0.977
            36          -0.11868        0.977
            37          -0.11618        0.977
            38          -0.11381        0.977
            39          -0.11156        0.977
            40          -0.10943        0.977
            41          -0.10739        0.977
            42          -0.10545        0.977
            43          -0.10361        0.977
            44          -0.10184        0.977
            45          -0.10015        0.977
            46          -0.09854        0.977
            47          -0.09699        0.977
            48          -0.09551        0.977
            49          -0.09408        0.977
            50          -0.09272        0.977
            51          -0.09140        0.977
            52          -0.09014        0.977
            53          -0.08892        0.977
            54          -0.08775        0.977
            55          -0.08662        0.977
            56          -0.08553        0.977
            57          -0.08448        0.977
            58          -0.08347        0.977
            59          -0.08249        0.977
            60          -0.08154        0.977
            61          -0.08062        0.977
            62          -0.07973        0.977
            63          -0.07887        0.977
            64          -0.07804        0.977
            65          -0.07723        0.977
            66          -0.07644        0.977
            67          -0.07568        0.977
            68          -0.07494        0.977
            69          -0.07423        0.977
            70          -0.07353        0.977
            71          -0.07285        0.977
            72          -0.07219        0.977
            73          -0.07155        0.977
            74          -0.07093        0.977
            75          -0.07032        0.977
            76          -0.06973        0.977
            77          -0.06915        0.977
            78          -0.06859        0.977
            79          -0.06804        0.977
            80          -0.06751        0.977
            81          -0.06699        0.977
            82          -0.06648        0.977
            83          -0.06599        0.977
            84          -0.06550        0.977
            85          -0.06503        0.977
            86          -0.06457        0.977
            87          -0.06412        0.977
            88          -0.06367        0.977
            89          -0.06324        0.977
            90          -0.06282        0.977
            91          -0.06241        0.977
            92          -0.06200        0.977
            93          -0.06161        0.977
            94          -0.06122        0.977
            95          -0.06084        0.977
            96          -0.06047        0.977
            97          -0.06011        0.977
            98          -0.05975        0.977
            99          -0.05941        0.977
         Final          -0.05906        0.977


• κ = 10
    ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -2.63906        0.018
             2          -1.20953        0.682
             3          -0.93455        0.881
             4          -0.74442        0.968
             5          -0.61355        0.977
             6          -0.52052        0.980
             7          -0.45174        0.980
             8          -0.39912        0.980
             9          -0.35767        0.980
            10          -0.32425        0.980
            11          -0.29677        0.980
            12          -0.27379        0.980
            13          -0.25430        0.980
            14          -0.23757        0.980
            15          -0.22307        0.980
            16          -0.21037        0.980
            17          -0.19917        0.980
            18          -0.18921        0.980
            19          -0.18031        0.980
            20          -0.17230        0.980
            21          -0.16505        0.980
            22          -0.15847        0.980
            23          -0.15247        0.980
            24          -0.14697        0.980
            25          -0.14191        0.980
            26          -0.13724        0.980
            27          -0.13293        0.980
            28          -0.12892        0.980
            29          -0.12519        0.980
            30          -0.12172        0.980
            31          -0.11847        0.980
            32          -0.11542        0.980
            33          -0.11256        0.980
            34          -0.10987        0.980
            35          -0.10734        0.980
            36          -0.10495        0.980
            37          -0.10269        0.980
            38          -0.10054        0.980
            39          -0.09851        0.980
            40          -0.09659        0.980
            41          -0.09475        0.980
            42          -0.09301        0.980
            43          -0.09134        0.980
            44          -0.08976        0.980
            45          -0.08824        0.980
            46          -0.08679        0.980
            47          -0.08540        0.980
            48          -0.08407        0.980
            49          -0.08280        0.980
            50          -0.08158        0.980
            51          -0.08040        0.980
            52          -0.07927        0.980
            53          -0.07818        0.980
            54          -0.07714        0.980
            55          -0.07613        0.980
            56          -0.07516        0.980
            57          -0.07422        0.980
            58          -0.07332        0.980
            59          -0.07244        0.980
            60          -0.07160        0.980
            61          -0.07078        0.980
            62          -0.06999        0.980
            63          -0.06923        0.980
            64          -0.06849        0.980
            65          -0.06777        0.980
            66          -0.06707        0.980
            67          -0.06640        0.980
            68          -0.06574        0.980
            69          -0.06511        0.980
            70          -0.06449        0.980
            71          -0.06389        0.980
            72          -0.06331        0.980
            73          -0.06274        0.980
            74          -0.06219        0.980
            75          -0.06165        0.980
            76          -0.06113        0.980
            77          -0.06062        0.980
            78          -0.06012        0.980
            79          -0.05964        0.980
            80          -0.05916        0.980
            81          -0.05870        0.980
            82          -0.05826        0.980
            83          -0.05782        0.980
            84          -0.05739        0.980
            85          -0.05697        0.980
            86          -0.05657        0.980
            87          -0.05617        0.980
            88          -0.05578        0.980
            89          -0.05540        0.980
            90          -0.05503        0.980
            91          -0.05466        0.980
            92          -0.05431        0.980
            93          -0.05396        0.980
            94          -0.05362        0.980
            95          -0.05328        0.980
            96          -0.05296        0.980
            97          -0.05264        0.980
            98          -0.05233        0.980
            99          -0.05202        0.980
         Final          -0.05172        0.980


• κ = 20
    ==> Training (100 iterations)

      Iteration    Log Likelihood    Accuracy
      ---------------------------------------
             1          -2.63906        0.018
             2          -1.20031        0.711
             3          -0.91984        0.910
             4          -0.72600        0.978
             5          -0.59375        0.980
             6          -0.50063        0.982
             7          -0.43237        0.982
             8          -0.38048        0.982
             9          -0.33985        0.982
            10          -0.30725        0.982
            11          -0.28054        0.982
            12          -0.25828        0.982
            13          -0.23946        0.982
            14          -0.22335        0.982
            15          -0.20940        0.982
            16          -0.19722        0.982
            17          -0.18649        0.982
            18          -0.17697        0.982
            19          -0.16846        0.982
            20          -0.16082        0.982
            21          -0.15392        0.982
            22          -0.14765        0.982
            23          -0.14194        0.982
            24          -0.13671        0.982
            25          -0.13190        0.982
            26          -0.12747        0.982
            27          -0.12337        0.982
            28          -0.11957        0.982
            29          -0.11604        0.982
            30          -0.11275        0.982
            31          -0.10967        0.982
            32          -0.10678        0.982
            33          -0.10408        0.982
            34          -0.10153        0.982
            35          -0.09913        0.982
            36          -0.09687        0.982
            37          -0.09473        0.982
            38          -0.09271        0.982
            39          -0.09079        0.982
            40          -0.08897        0.982
            41          -0.08724        0.982
            42          -0.08559        0.982
            43          -0.08402        0.982
            44          -0.08252        0.982
            45          -0.08109        0.982
            46          -0.07972        0.982
            47          -0.07841        0.982
            48          -0.07716        0.982
            49          -0.07596        0.982
            50          -0.07480        0.982
            51          -0.07370        0.982
            52          -0.07263        0.982
            53          -0.07161        0.982
            54          -0.07062        0.982
            55          -0.06967        0.982
            56          -0.06876        0.982
            57          -0.06788        0.982
            58          -0.06702        0.982
            59          -0.06620        0.982
            60          -0.06541        0.982
            61          -0.06464        0.982
            62          -0.06389        0.982
            63          -0.06317        0.982
            64          -0.06248        0.982
            65          -0.06180        0.982
            66          -0.06115        0.982
            67          -0.06051        0.982
            68          -0.05990        0.982
            69          -0.05930        0.982
            70          -0.05872        0.982
            71          -0.05815        0.982
            72          -0.05761        0.982
            73          -0.05707        0.982
            74          -0.05655        0.982
            75          -0.05605        0.982
            76          -0.05556        0.982
            77          -0.05508        0.982
            78          -0.05461        0.982
            79          -0.05416        0.982
            80          -0.05371        0.982
            81          -0.05328        0.982
            82          -0.05286        0.982
            83          -0.05245        0.982
            84          -0.05205        0.982
            85          -0.05166        0.982
            86          -0.05128        0.982
            87          -0.05090        0.982
            88          -0.05054        0.982
            89          -0.05018        0.982
            90          -0.04983        0.982
            91          -0.04949        0.982
            92          -0.04916        0.982
            93          -0.04883        0.982
            94          -0.04851        0.982
            95          -0.04820        0.982
            96          -0.04789        0.982
            97          -0.04759        0.982
            98          -0.04730        0.982
            99          -0.04701        0.982
         Final          -0.04673        0.982